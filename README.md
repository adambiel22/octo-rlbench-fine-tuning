# octo-rlbench-fine-tuning
Fine-tuning Octo model with data generated by RLBench


## Step 1. Generate data with RLBench

The script that generates the dataset is [RLBench/rlbench/dataset_generator.py](RLBench/rlbench/dataset_generator.py). To use it follow the steps below.

1. Make virtual environment and activate it

```bash
python3 -m venv rlbench-venv
source rlbench-venv/bin/activate
```

2. Install CoppeliaSim

```bash
# set env variables
export COPPELIASIM_ROOT=${HOME}/CoppeliaSim
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT

wget https://downloads.coppeliarobotics.com/V4_1_0/CoppeliaSim_Edu_V4_1_0_Ubuntu20_04.tar.xz
mkdir -p $COPPELIASIM_ROOT && tar -xf CoppeliaSim_Edu_V4_1_0_Ubuntu20_04.tar.xz -C $COPPELIASIM_ROOT --strip-components 1
rm -rf CoppeliaSim_Edu_V4_1_0_Ubuntu20_04.tar.xz
```

3. Install the RLBench python package:

```bash
pip install -e RLBench
pip install gymnasium
```

4. Run [RLBench/rlbench/dataset_generator.py](RLBench/rlbench/dataset_generator.py) script:
```bash
python RLBench/rlbench/dataset_generator.py \
  --tasks place_shape_in_shape_sorter \
  --save_path generated_datasets \
  --image_size 256 256 \
  --renderer opengl3 \
  --processes 4 \
  --episodes_per_task 10 \
  --variations 5 \
  --arm_max_velocity 1.0 \
  --arm_max_acceleration 4.0 \
  --robot_setup ur5
```
It will take up to several dozen minutes. For testing purposes reduce `variations` and `episodes_per_task`

To examine meaning of the arguments run:
```bash
python RLBench/rlbench/dataset_generator.py --help
```

It should create `generated_datasets/place_shape_in_shape_sorter`.


### Troubleshooting

#### Problem

Error log:
```
ImportError: libcoppeliaSim.so.1: cannot open shared object file: No such file or directory
```

#### Solution

Run:
```bash
export COPPELIASIM_ROOT=${HOME}/CoppeliaSim
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
```

Or add these lines to the end of `rlbench-venv/bin/activate` script to export those environment variables every time you activate the rlbench-venv.

## Step 2. Convert data to RLDS format

1. Create a conda environment using the provided environment.yml file (use `rlds_dataset_builder/environment_macos.yml` or `rlds_dataset_builder/environment_macos.yml` depending on the operating system you're using):
```bash
conda env create -f rlds_dataset_builder/environment_ubuntu.yml
```

Then activate the environment using:
```bash
conda activate rlds_env
```

If you want to manually create an environment, the key packages to install are `tensorflow`, 
`tensorflow_datasets`, `tensorflow_hub`, `apache_beam`, `matplotlib`, `plotly` and `wandb`.

2. Specify the generated RLBench dataset path in the constructor of `RLBenchDataset` class in the `rlds_dataset_builder/rl_bench_dataset/rl_bench_dataset.py` file. Eg.:

```python
class RLBenchDataset(tfds.core.GeneratorBasedBuilder):
    """DatasetBuilder for example dataset."""

    // ...

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.rlbench_generated_dataset_path = "../../generated_datasets/place_shape_in_shape_sorter"
        // ...
```


3. Run RLDS Dataset Creation
```bash
cd rlds_dataset_builder/rl_bench_dataset
tfds build
```

This should create a new dataset in `~/tensorflow_datasets/rl_bench_dataset`.

4. To visualize the dataset run

```bash
cd rlds_dataset_builder
python visualize_dataset.py rl_bench_dataset
```


## Step 3. Train the model

1. Copy the dataset in RLDS format to the entropy cluster. Eg.:

```bash
scp -r ~/tensorflow_datasets/rl_bench_dataset entropy_username@entropy.mimuw.edu.pl:/home/entropy_username/tensorflow_datasets
```

2. Login to entropy. Eg.:

```bash
ssh entropy_username@entropy.mimuw.edu.pl
```

3. Clone or copy the repository.

```bash
git clone git@github.com:adambiel22/octo-rlbench-fine-tuning.git
cd octo-rlbench-fine-tuning
```

4. Create python virtual environment.

```bash
cd octo
python3 -m venv octo-venv
source octo-venv/bin/activate
pip install -e .
pip install -r requirements.txt
pip install --upgrade "jax[cuda12_pip]==0.4.20" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
```

5. Review the sbatch script `fine_tuning_job.sh`. For sbatch details refer to: [https://entropy-doc.mimuw.edu.pl/submittingjobs.html#using-sbatch](https://entropy-doc.mimuw.edu.pl/submittingjobs.html#using-sbatch). Especially specify correct `partition`, `qos` and paths.
```bash
#!/bin/bash
#
#SBATCH --job-name=fine_tune_octo
#SBATCH --partition=a6000
#SBATCH --qos=2gpu3d
#SBATCH --gres=gpu:1
#SBATCH --time=3:00:00
#SBATCH --output=fine_tune_octo.txt

# full fine-tuning rlbench
python examples/02_finetune_new_observation_action_rl_bench.py \
  --pretrained_path=hf://rail-berkeley/octo-base-1.5 \
  --data_dir=~/tensorflow_datasets \
  --save_dir=~/octo-rlbench-fine-tuning/octo/checkpoint_rlbench \
  --batch_size=60
```

6. Run sbatch script.
```bash
sbatch fine_tuning_job.sh
```

## Step 4. Evaluate the model

1. Navigate to `octo-rlbench-fine-tuning/octo` directory in your local machine.
2. Create python virtual environment.
```bash
python3 -m venv octo-venv
source octo-venv/bin/activate
pip install -e .
pip install -r requirements.txt
pip install --upgrade "jax==0.4.20"
```

3. Copy checkpoint from entropy cluster. Eg.:
```bash
scp -r entropy_username@entropy.mimuw.edu.pl:/home/entropy_username/octo-rlbench-fine-tuning/octo/checkpoint_rlbench .
```

4. Run evaluation
```bash
python examples/03_eval_finetuned_rlbench.py --finetuned_path=checkpoint_rlbench
```