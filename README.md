# octo-rlbench-fine-tuning
Fine-tuning Octo model with data generated by RLBench


## Step 1. Generate data with RLBench

### Install RLBench

To generate data you need RLBench. You have two options:

1. if you don't plan to change anything in the RLBench code, you can simply follow the [installation steps from RLBench repo](https://github.com/stepjam/RLBench?tab=readme-ov-file#install).
2. if you wish to have a local, editable version installed, you can use the submodule provided in this repo.
The installation steps are the same, you simply have to install RLBench from local directory with `pip install -e RLBench`

Notes:

1. Before using `RLBench`, you also need to install `gymnasium` with `pip install gymnasium`.
2. If you are using a submodule, make sure to update to the most recent version with `git submodule update --init --recursive`

### Generate the data

The `ur5_dataset_generator.py` script generates the data.
It is a slightly changed version of `dataset_generator.py` from the original RLBench repository.
It allows to generate data with UR5 robot.
Example usage:

```bash
python ur5_dataset_generator.py \
  --tasks place_shape_in_shape_sorter \
  --save_path generated_datasets \
  --image_size 256 256 \
  --renderer opengl3 \
  --processes 4 \
  --episodes_per_task 10 \
  --variations 5 \
  --arm_max_velocity 1.0 \
  --arm_max_acceleration 4.0 \
  --robot_setup ur5
```

This should create a dataset in the `generated_datasets/place_shape_in_shape_sorter` directory.

#### Notes and troubleshooting:

1. It can take up to several dozen minutes to generate the data.
For testing purposes you can reduce `variations` and `episodes_per_task`
2. To examine meaning of the arguments run `python ur5_dataset_generator.py --help`

3. If you're getting `ImportError: libcoppeliaSim.so.1: cannot open shared object file: No such file or directory` make sure that shell variables for Coppelia are exported (i.e. the ones exported during installation).
If you are using a pip environment probably the best idea is to add:

```bash
export COPPELIASIM_ROOT=${HOME}/CoppeliaSim
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT
```

at the end of `bin/activate` script to export the variables every time the virtual environment is activated.

## Step 2. Convert data to RLDS format

1. Create a conda environment using the provided environment.yml file (use `rlds_dataset_builder/environment_macos.yml` or `rlds_dataset_builder/environment_macos.yml` depending on the operating system you're using):
```bash
conda env create -f rlds_dataset_builder/environment_ubuntu.yml
```

Then activate the environment using:
```bash
conda activate rlds_env
```

If you want to manually create an environment, the key packages to install are `tensorflow`, 
`tensorflow_datasets`, `tensorflow_hub`, `apache_beam`, `matplotlib`, `plotly` and `wandb`.

2. Specify the generated RLBench dataset path in the constructor of `RLBenchDataset` class in the `rlds_dataset_builder/rl_bench_dataset/rl_bench_dataset.py` file. Eg.:

```python
class RLBenchDataset(tfds.core.GeneratorBasedBuilder):
    """DatasetBuilder for example dataset."""

    // ...

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.rlbench_generated_dataset_path = "../../generated_datasets/place_shape_in_shape_sorter"
        // ...
```


3. Run RLDS Dataset Creation
```bash
cd rlds_dataset_builder/rl_bench_dataset
tfds build
```

This should create a new dataset in `~/tensorflow_datasets/rl_bench_dataset`.

4. To visualize the dataset run

```bash
cd rlds_dataset_builder
python visualize_dataset.py rl_bench_dataset
```


## Step 3. Train the model

1. Copy the dataset in RLDS format to the entropy cluster. Eg.:

```bash
scp -r ~/tensorflow_datasets/rl_bench_dataset entropy_username@entropy.mimuw.edu.pl:/home/entropy_username/tensorflow_datasets
```

2. Login to entropy. Eg.:

```bash
ssh entropy_username@entropy.mimuw.edu.pl
```

3. Clone or copy the repository.

```bash
git clone git@github.com:adambiel22/octo-rlbench-fine-tuning.git
cd octo-rlbench-fine-tuning
```

4. Create python virtual environment.

```bash
cd octo
python3 -m venv octo-venv
source octo-venv/bin/activate
pip install -e .
pip install -r requirements.txt
pip install --upgrade "jax[cuda12_pip]==0.4.20" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
pip install tensorflow[and-cuda]
pip install tensorflow==2.15.0
```

5. Log in to WandB to track the training.

6. Check the `sbatch' script `fine_tuning_job.sh`. For `sbatch` details see [https://entropy-doc.mimuw.edu.pl/submittingjobs.html#using-sbatch](https://entropy-doc.mimuw.edu.pl/submittingjobs.html#using-sbatch). Make sure you specify the correct `partition', `qos' and all paths.
```bash
#!/bin/bash
#
#SBATCH --job-name=fine_tune_octo
#SBATCH --partition=a6000
#SBATCH --qos=2gpu3d
#SBATCH --gres=gpu:1
#SBATCH --time=3:00:00
#SBATCH --output=fine_tune_octo.txt

# full fine-tuning rlbench
python examples/02_finetune_new_observation_action_rl_bench.py \
  --pretrained_path=hf://rail-berkeley/octo-base-1.5 \
  --data_dir=~/tensorflow_datasets \
  --save_dir=~/octo-rlbench-fine-tuning/octo/checkpoint_rlbench \
  --batch_size=60
```

7. Run sbatch script.
```bash
sbatch fine_tuning_job.sh
```

The training can take up to 90 minutes. For testing purposes you can reduce number of iterations at the bottom of `examples/02_finetune_new_observation_action_rl_bench.py` file.

## Step 4. Evaluate the model

1. Navigate to `octo-rlbench-fine-tuning/octo` directory in your local machine.
2. Create python virtual environment.
```bash
python3 -m venv octo-venv-eval
source octo-venv-eval/bin/activate
pip install -e .
pip install -r requirements.txt
pip install --upgrade "jax==0.4.20"
pip install --upgrade "jaxlib==0.4.20"
pip install gymnasium

export COPPELIASIM_ROOT=${HOME}/CoppeliaSim
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$COPPELIASIM_ROOT
export QT_QPA_PLATFORM_PLUGIN_PATH=$COPPELIASIM_ROOT

pip install -e ../RLBench/
```

3. Copy the checkpoint from the Entropy cluster. Eg.:
```bash
scp -r entropy_username@entropy.mimuw.edu.pl:/home/entropy_username/octo-rlbench-fine-tuning/octo/checkpoint_rlbench .
```

4. Log in to WandB to track the evaluation.

5. Run evaluation
```bash
python examples/03_eval_finetuned_rlbench.py --finetuned_path=checkpoint_rlbench
```
